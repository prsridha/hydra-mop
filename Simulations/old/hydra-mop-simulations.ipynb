{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bccfc694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import string\n",
    "import random\n",
    "import itertools\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca2c479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0894af5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_combinations(param_grid):\n",
    "    param_keys = list(param_grid.keys())\n",
    "\n",
    "    params_list = [param_grid[key] for key in param_keys]\n",
    "    combinations = list(itertools.product(*params_list))\n",
    "\n",
    "    param_combinations = []\n",
    "    for comb in combinations:\n",
    "        d = {}\n",
    "        for i in range(len(comb)):\n",
    "            d[param_keys[i]] = comb[i]\n",
    "        param_combinations.append(d)\n",
    "\n",
    "    return param_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0a990fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_groups(models, workers):    \n",
    "    gpu_counts = [len(i) for i in workers.values()]\n",
    "    avg_gpus = math.ceil(sum(gpu_counts)/len(gpu_counts))\n",
    "    \n",
    "    model_groups = []\n",
    "    for i in range(0, len(models), avg_gpus):\n",
    "        model_groups.append(tuple(models[i:i + avg_gpus]))\n",
    "    \n",
    "    return model_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5eb5c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_runnable_model_group(worker, model_groups, model_group_on_worker, mgw_pairs):\n",
    "        runnable_model_group = -1\n",
    "        random.shuffle(model_groups)\n",
    "        for mg in model_groups:\n",
    "            if not (mgw_pairs[mg][worker]):\n",
    "                if model_group_on_worker[mg] == -1:\n",
    "                    runnable_model_group = mg\n",
    "                    break\n",
    "        return runnable_model_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4679f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_finished(worker, exec_id):\n",
    "    with open(\"check_finished_\" + str(worker) + \".txt\", \"r\") as f:\n",
    "        s = f.read().split(\"\\n\")\n",
    "    return exec_id in s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c5b606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a336fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    "workers = {0: [\"GPU1\", \"GPU2\"],\n",
    "           1: [\"GPU1\", \"GPU2\"],\n",
    "           2: [\"GPU1\", \"GPU2\"],\n",
    "           3: [\"GPU1\", \"GPU2\"]\n",
    "            }\n",
    "train_shards = [\"shard1\", \"shard2\", \"shard3\", \"shard4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc2a67e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'learning_rate': [1e-2, 1e-3],\n",
    "        'embed_size': [256, 512],\n",
    "        'hidden_size': [256, 512],\n",
    "        'batch_size': [128]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78715673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_stuff():\n",
    "    param_combinations = find_combinations(param_grid)\n",
    "    print(\"Grid Search space:\")\n",
    "    print(param_combinations)\n",
    "    \n",
    "    model_id_to_mst_mapping = {}\n",
    "    for i in range(len(models)):\n",
    "        model_id_to_mst_mapping[models[i]] = param_combinations[i]\n",
    "    print(model_id_to_mst_mapping)\n",
    "        \n",
    "    model_groups = create_model_groups(models, workers)\n",
    "    print(\"Model Groups:\")\n",
    "    print(model_groups)\n",
    "        \n",
    "    model_group_on_worker = {}\n",
    "    for i in range(len(model_groups)):\n",
    "        model_group_on_worker[model_groups[i]] = -1\n",
    "    \n",
    "    worker_running_model_group = {}\n",
    "    for w in workers:\n",
    "        worker_running_model_group[w] = -1\n",
    "        \n",
    "#     mgw_pairs = [[False] * len(workers)] * len(model_groups)\n",
    "    mgw_pairs = {}\n",
    "    for mg in model_groups:\n",
    "        mgw_pairs[mg] = [False] * len(workers)\n",
    "    \n",
    "    return model_groups, model_group_on_worker, worker_running_model_group, mgw_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b48f5365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_hydra_job(epoch, worker, mg):\n",
    "    print(\"Scheduling epoch {} of model_group {} on worker {}\".format(epoch, mg, worker))\n",
    "    \n",
    "    exec_id = ''.join(random.choice(string.ascii_lowercase + string.digits) for _ in range(32))\n",
    "    data = {\n",
    "        \"epoch\": epoch,\n",
    "        \"models\": str(mg),\n",
    "        \"exec_id\": str(exec_id)\n",
    "    }\n",
    "    worker_ip = \"http://localhost:\" + str(8000 + worker) + \"/hydra\"\n",
    "    requests.post(url=worker_ip, json=data)\n",
    "\n",
    "    return exec_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a16a537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add validation stuff: is_last_worker, etc.\n",
    "def scheduler(epoch, model_groups, workers, model_group_on_worker, mgw_pairs, worker_running_model_group):\n",
    "    model_groups_to_build = set(model_groups)\n",
    "    exec_id_on_worker = {x:None for x in range(len(workers))}\n",
    "    \n",
    "    \n",
    "    while(len(model_groups_to_build) > 0):\n",
    "        for worker in workers:\n",
    "            if worker_running_model_group[worker] == -1:\n",
    "                mg = get_runnable_model_group(worker, model_groups, model_group_on_worker, mgw_pairs)\n",
    "                if mg != -1:\n",
    "                    exec_id = launch_hydra_job(epoch, worker, mg)\n",
    "                    \n",
    "                    model_group_on_worker[mg] = worker\n",
    "                    worker_running_model_group[worker] = mg\n",
    "                    exec_id_on_worker[worker] = exec_id\n",
    "                    print(\"Sent models {} to build on worker {} \".format(\n",
    "                            str(mg), str(worker)))\n",
    "            else:\n",
    "                mg = worker_running_model_group[worker]\n",
    "                exec_id = exec_id_on_worker[worker]\n",
    "                completed = check_finished(worker, exec_id)\n",
    "#                 print(\"In else, checking {}\".format(exec_id))\n",
    "\n",
    "                if completed:\n",
    "                    print(\"Received Models {} built on worker {}\".format(str(mg), str(worker)))\n",
    "                    model_group_on_worker[mg] = -1\n",
    "                    worker_running_model_group[worker] = -1\n",
    "                    mgw_pairs[mg][worker] = True\n",
    "\n",
    "                    model_group_done = True\n",
    "                    for i in range(len(workers)):\n",
    "                        if not mgw_pairs[mg][i]:\n",
    "                            model_group_done = False\n",
    "                            break\n",
    "                    if model_group_done:\n",
    "                        model_groups_to_build.remove(mg)\n",
    "    print(\"Done with all epochs :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b57f2a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search():\n",
    "    num_epochs = 2\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        print(\"EPOCH: \" + str(i+1))\n",
    "        model_groups, model_group_on_worker, worker_running_model_group, mgw_pairs = init_stuff()\n",
    "        scheduler(i, model_groups, workers, model_group_on_worker, mgw_pairs, worker_running_model_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f87044a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n",
      "Grid Search space:\n",
      "[{'learning_rate': 0.01, 'embed_size': 256, 'hidden_size': 256, 'batch_size': 128}, {'learning_rate': 0.01, 'embed_size': 256, 'hidden_size': 512, 'batch_size': 128}, {'learning_rate': 0.01, 'embed_size': 512, 'hidden_size': 256, 'batch_size': 128}, {'learning_rate': 0.01, 'embed_size': 512, 'hidden_size': 512, 'batch_size': 128}, {'learning_rate': 0.001, 'embed_size': 256, 'hidden_size': 256, 'batch_size': 128}, {'learning_rate': 0.001, 'embed_size': 256, 'hidden_size': 512, 'batch_size': 128}, {'learning_rate': 0.001, 'embed_size': 512, 'hidden_size': 256, 'batch_size': 128}, {'learning_rate': 0.001, 'embed_size': 512, 'hidden_size': 512, 'batch_size': 128}]\n",
      "{'A': {'learning_rate': 0.01, 'embed_size': 256, 'hidden_size': 256, 'batch_size': 128}, 'B': {'learning_rate': 0.01, 'embed_size': 256, 'hidden_size': 512, 'batch_size': 128}, 'C': {'learning_rate': 0.01, 'embed_size': 512, 'hidden_size': 256, 'batch_size': 128}, 'D': {'learning_rate': 0.01, 'embed_size': 512, 'hidden_size': 512, 'batch_size': 128}, 'E': {'learning_rate': 0.001, 'embed_size': 256, 'hidden_size': 256, 'batch_size': 128}, 'F': {'learning_rate': 0.001, 'embed_size': 256, 'hidden_size': 512, 'batch_size': 128}, 'G': {'learning_rate': 0.001, 'embed_size': 512, 'hidden_size': 256, 'batch_size': 128}, 'H': {'learning_rate': 0.001, 'embed_size': 512, 'hidden_size': 512, 'batch_size': 128}}\n",
      "Model Groups:\n",
      "[('A', 'B'), ('C', 'D'), ('E', 'F'), ('G', 'H')]\n",
      "Scheduling epoch 0 of model_group ('C', 'D') on worker 0\n",
      "Sent models ('C', 'D') to build on worker 0 \n",
      "Scheduling epoch 0 of model_group ('G', 'H') on worker 1\n",
      "Sent models ('G', 'H') to build on worker 1 \n",
      "Scheduling epoch 0 of model_group ('E', 'F') on worker 2\n",
      "Sent models ('E', 'F') to build on worker 2 \n",
      "Scheduling epoch 0 of model_group ('A', 'B') on worker 3\n",
      "Sent models ('A', 'B') to build on worker 3 \n",
      "Received Models ('G', 'H') built on worker 1\n",
      "Received Models ('C', 'D') built on worker 0\n",
      "Scheduling epoch 0 of model_group ('C', 'D') on worker 1\n",
      "Sent models ('C', 'D') to build on worker 1 \n",
      "Received Models ('E', 'F') built on worker 2\n",
      "Scheduling epoch 0 of model_group ('E', 'F') on worker 0\n",
      "Sent models ('E', 'F') to build on worker 0 \n",
      "Scheduling epoch 0 of model_group ('G', 'H') on worker 2\n",
      "Sent models ('G', 'H') to build on worker 2 \n",
      "Received Models ('E', 'F') built on worker 0\n",
      "Received Models ('A', 'B') built on worker 3\n",
      "Scheduling epoch 0 of model_group ('A', 'B') on worker 0\n",
      "Sent models ('A', 'B') to build on worker 0 \n",
      "Scheduling epoch 0 of model_group ('E', 'F') on worker 3\n",
      "Sent models ('E', 'F') to build on worker 3 \n",
      "Received Models ('G', 'H') built on worker 2\n",
      "Received Models ('C', 'D') built on worker 1\n",
      "Scheduling epoch 0 of model_group ('C', 'D') on worker 2\n",
      "Sent models ('C', 'D') to build on worker 2 \n",
      "Received Models ('A', 'B') built on worker 0\n",
      "Scheduling epoch 0 of model_group ('A', 'B') on worker 1\n",
      "Sent models ('A', 'B') to build on worker 1 \n",
      "Scheduling epoch 0 of model_group ('G', 'H') on worker 0\n",
      "Sent models ('G', 'H') to build on worker 0 \n",
      "Received Models ('E', 'F') built on worker 3\n",
      "Received Models ('C', 'D') built on worker 2\n",
      "Scheduling epoch 0 of model_group ('C', 'D') on worker 3\n",
      "Sent models ('C', 'D') to build on worker 3 \n",
      "Received Models ('G', 'H') built on worker 0\n",
      "Received Models ('A', 'B') built on worker 1\n",
      "Scheduling epoch 0 of model_group ('A', 'B') on worker 2\n",
      "Sent models ('A', 'B') to build on worker 2 \n",
      "Scheduling epoch 0 of model_group ('E', 'F') on worker 1\n",
      "Sent models ('E', 'F') to build on worker 1 \n",
      "Received Models ('C', 'D') built on worker 3\n",
      "Scheduling epoch 0 of model_group ('G', 'H') on worker 3\n",
      "Sent models ('G', 'H') to build on worker 3 \n",
      "Received Models ('A', 'B') built on worker 2\n",
      "Received Models ('G', 'H') built on worker 3\n",
      "Received Models ('E', 'F') built on worker 1\n",
      "Done with all epochs :)\n",
      "EPOCH: 2\n",
      "Grid Search space:\n",
      "[{'learning_rate': 0.01, 'embed_size': 256, 'hidden_size': 256, 'batch_size': 128}, {'learning_rate': 0.01, 'embed_size': 256, 'hidden_size': 512, 'batch_size': 128}, {'learning_rate': 0.01, 'embed_size': 512, 'hidden_size': 256, 'batch_size': 128}, {'learning_rate': 0.01, 'embed_size': 512, 'hidden_size': 512, 'batch_size': 128}, {'learning_rate': 0.001, 'embed_size': 256, 'hidden_size': 256, 'batch_size': 128}, {'learning_rate': 0.001, 'embed_size': 256, 'hidden_size': 512, 'batch_size': 128}, {'learning_rate': 0.001, 'embed_size': 512, 'hidden_size': 256, 'batch_size': 128}, {'learning_rate': 0.001, 'embed_size': 512, 'hidden_size': 512, 'batch_size': 128}]\n",
      "{'A': {'learning_rate': 0.01, 'embed_size': 256, 'hidden_size': 256, 'batch_size': 128}, 'B': {'learning_rate': 0.01, 'embed_size': 256, 'hidden_size': 512, 'batch_size': 128}, 'C': {'learning_rate': 0.01, 'embed_size': 512, 'hidden_size': 256, 'batch_size': 128}, 'D': {'learning_rate': 0.01, 'embed_size': 512, 'hidden_size': 512, 'batch_size': 128}, 'E': {'learning_rate': 0.001, 'embed_size': 256, 'hidden_size': 256, 'batch_size': 128}, 'F': {'learning_rate': 0.001, 'embed_size': 256, 'hidden_size': 512, 'batch_size': 128}, 'G': {'learning_rate': 0.001, 'embed_size': 512, 'hidden_size': 256, 'batch_size': 128}, 'H': {'learning_rate': 0.001, 'embed_size': 512, 'hidden_size': 512, 'batch_size': 128}}\n",
      "Model Groups:\n",
      "[('A', 'B'), ('C', 'D'), ('E', 'F'), ('G', 'H')]\n",
      "Scheduling epoch 1 of model_group ('E', 'F') on worker 0\n",
      "Sent models ('E', 'F') to build on worker 0 \n",
      "Scheduling epoch 1 of model_group ('A', 'B') on worker 1\n",
      "Sent models ('A', 'B') to build on worker 1 \n",
      "Scheduling epoch 1 of model_group ('G', 'H') on worker 2\n",
      "Sent models ('G', 'H') to build on worker 2 \n",
      "Scheduling epoch 1 of model_group ('C', 'D') on worker 3\n",
      "Sent models ('C', 'D') to build on worker 3 \n",
      "Received Models ('A', 'B') built on worker 1\n",
      "Received Models ('E', 'F') built on worker 0\n",
      "Scheduling epoch 1 of model_group ('E', 'F') on worker 1\n",
      "Sent models ('E', 'F') to build on worker 1 \n",
      "Received Models ('G', 'H') built on worker 2\n",
      "Scheduling epoch 1 of model_group ('A', 'B') on worker 0\n",
      "Sent models ('A', 'B') to build on worker 0 \n",
      "Received Models ('C', 'D') built on worker 3\n",
      "Received Models ('A', 'B') built on worker 0\n",
      "Scheduling epoch 1 of model_group ('A', 'B') on worker 2\n",
      "Sent models ('A', 'B') to build on worker 2 \n",
      "Scheduling epoch 1 of model_group ('G', 'H') on worker 3\n",
      "Sent models ('G', 'H') to build on worker 3 \n",
      "Scheduling epoch 1 of model_group ('C', 'D') on worker 0\n",
      "Sent models ('C', 'D') to build on worker 0 \n",
      "Received Models ('C', 'D') built on worker 0\n",
      "Received Models ('E', 'F') built on worker 1\n",
      "Scheduling epoch 1 of model_group ('C', 'D') on worker 1\n",
      "Sent models ('C', 'D') to build on worker 1 \n",
      "Received Models ('A', 'B') built on worker 2\n",
      "Received Models ('C', 'D') built on worker 1\n",
      "Scheduling epoch 1 of model_group ('E', 'F') on worker 2\n",
      "Sent models ('E', 'F') to build on worker 2 \n",
      "Received Models ('G', 'H') built on worker 3\n",
      "Scheduling epoch 1 of model_group ('G', 'H') on worker 0\n",
      "Sent models ('G', 'H') to build on worker 0 \n",
      "Scheduling epoch 1 of model_group ('A', 'B') on worker 3\n",
      "Sent models ('A', 'B') to build on worker 3 \n",
      "Received Models ('E', 'F') built on worker 2\n",
      "Scheduling epoch 1 of model_group ('C', 'D') on worker 2\n",
      "Sent models ('C', 'D') to build on worker 2 \n",
      "Received Models ('A', 'B') built on worker 3\n",
      "Scheduling epoch 1 of model_group ('E', 'F') on worker 3\n",
      "Sent models ('E', 'F') to build on worker 3 \n",
      "Received Models ('G', 'H') built on worker 0\n",
      "Scheduling epoch 1 of model_group ('G', 'H') on worker 1\n",
      "Sent models ('G', 'H') to build on worker 1 \n",
      "Received Models ('C', 'D') built on worker 2\n",
      "Received Models ('E', 'F') built on worker 3\n",
      "Received Models ('G', 'H') built on worker 1\n",
      "Done with all epochs :)\n"
     ]
    }
   ],
   "source": [
    "grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26bfa6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fa9b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03716263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
